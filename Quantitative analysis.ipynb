{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AAPL Vs. MSFT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing advanced statistical methods to understand, analyze, and compare the inherent risk in two stocks with Bollinger bands, Conditional Value at Risk, Kurtosis analysis, Shapiro-Wilk normality test, and back-test maximum drawdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Function\n",
    "def ticker_to_path(ticker, base_dir=\"stocks_DJIA\"):\n",
    "    \"\"\"Create the images directory if it does not exist.\"\"\"\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    \"\"\"Return CSV file path given ticker symbol.\"\"\"\n",
    "    return os.path.join(base_dir, \"{}.csv\".format(str(ticker)))\n",
    "\n",
    "\n",
    "def get_data(tickers, dates):\n",
    "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
    "    df = pd.DataFrame(index=dates)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index = df.index.tz_localize(None)\n",
    "    print(f\"df head: {df.head()}\")\n",
    "\n",
    "    if 'SPY' not in tickers:  # add SPY for reference, if absent\n",
    "        tickers.insert(0, 'SPY')\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df_temp = pd.read_csv(ticker_to_path(ticker), \n",
    "                              index_col=\"date\", \n",
    "                              parse_dates=True,\n",
    "                              usecols=['date','Adj Close'],\n",
    "                       na_values=['nan'])\n",
    "        \n",
    "        df_temp = df_temp.rename(columns={'Adj Close': ticker})\n",
    "        df_temp.index = pd.to_datetime(df_temp.index)\n",
    "        df_temp.index = df_temp.index.tz_localize(None)\n",
    "        print(f\"df_temp head: {df_temp.head()}\")\n",
    "        df = df.join(df_temp)\n",
    "        if ticker == 'SPY': #Drop dates SPY did not trade\n",
    "            df = df.dropna(subset=[\"SPY\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define a date range\n",
    "dates = pd.date_range('2017-12-12', '2018-12-14')\n",
    "\n",
    "# Choose stock symbols to read\n",
    "tickers = [\"AAPL\", \"MSFT\"]\n",
    "\n",
    "# Get stock data\n",
    "df = get_data(tickers, dates)\n",
    "    \n",
    "df = df.dropna(how=\"any\")\n",
    "\n",
    "#df.rename(columns={'BRK-A': 'AAPL'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forms of data\n",
    "prices = df.iloc[1:]\n",
    "returns = np.log(df / df.shift(1)).iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_brk(returns):\n",
    "    # Create a matrix of [returns, market]\n",
    "    brk_m = returns.cov().iloc[0,1]\n",
    "\n",
    "    # Return the covariance of m divided by the standard deviation of the market returns\n",
    "    return brk_m / returns['SPY'].var()\n",
    "\n",
    "def beta_MSFT(returns):\n",
    "    # Create a matrix of [returns, market]\n",
    "    MSFT_m = returns.cov().iloc[0,2]\n",
    "\n",
    "    # Return the covariance of m divided by the standard deviation of the market returns\n",
    "    return MSFT_m / returns['SPY'].var()\n",
    "\n",
    "print(\"Annualized Beta for AAPL: \",beta_brk(returns))\n",
    "print(\"Annualized Beta for MSFT: \",beta_MSFT(returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bollinger Bands"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part,we compute advanced statistical methods to analyze the investment horizon for both stocks in the past trading-year (252 days). We first introduce the Bollinger bands as a technical indicator for the behavior of the volatility and to explain mean-reversion for both stocks. Bollinger bands consist of computing the moving average for the adjusted closing price for AAPL in a rolling basis of 21 days (monthly) and computing rolling standard deviations of the price. The upper band represents two standard deviations above the moving average and the lower band represents two standard deviations below the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving averages (21 days)\n",
    "# Compute Rolling mean using 21 days window.\n",
    "rm_brk = prices[\"AAPL\"].rolling(window=21, center=False).mean()\n",
    "\n",
    "rstd_brk = prices[\"AAPL\"].rolling(window=21, center=False).std()\n",
    "\n",
    "upper_band = rm_brk + rstd_brk * 2\n",
    "lower_band = rm_brk - rstd_brk * 2\n",
    "\n",
    "print(f\"upper_band: {upper_band[-1]}\")\n",
    "print(f\"lower_band: {lower_band[-1]}\")\n",
    "print(f\"prices: {prices['AAPL'][-1]}\")\n",
    "\n",
    "# Plot BRK values, rolling mean and Bollinger Bands\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = prices['AAPL'].plot(title=\"AAPL Bollinger Bands\", label='AAPL',color=\"#002080\")\n",
    "rm_brk.plot(label='Rolling mean', ax=ax, color=\"r\",linewidth=2) #.annotate(f\"{upper_band[-1]}\", xy=(prices['AAPL'][-1]))\n",
    "upper_band.plot(label='Upper band', ax=ax,linewidth=2,color=\"#ff4d4d\",style='--')\n",
    "lower_band.plot(label='Lower band', ax=ax,linewidth=2,color=\"#ff4d4d\",style='--')\n",
    "\n",
    "\n",
    "# Add axis labels and legends\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax.legend(loc='lower right')\n",
    "plt.savefig('data/AAPL_bb.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the figure above, we observe that AAPL’s Bollinger bands expand for the first months of the year, then contracting significantly, and lastly starting to expand again. This behavior shows us that AAPL’s price has an expected incremental volatility which increases perceived risk, and as a result, trading opportunities for statistical arbitrage and other methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Rolling mean using 21 days window.\n",
    "rm_brk = prices[\"MSFT\"].rolling(window=21, center=False).mean()\n",
    "\n",
    "rstd_brk = prices[\"MSFT\"].rolling(window=21, center=False).std()\n",
    "\n",
    "upper_band = rm_brk + rstd_brk * 2\n",
    "lower_band = rm_brk - rstd_brk * 2\n",
    "\n",
    "# Plot BRK values, rolling mean and Bollinger Bands\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = prices['MSFT'].plot(title=\"MSFT Bollinger Bands\", label='MSFT',color=\"#FFA200\")\n",
    "rm_brk.plot(label='Rolling mean', ax=ax, color=\"r\",linewidth=2)\n",
    "upper_band.plot(label='Upper band', ax=ax,linewidth=2,color=\"#ff4d4d\",style='--')\n",
    "lower_band.plot(label='Lower band', ax=ax,linewidth=2,color=\"#ff4d4d\",style='--')\n",
    "\n",
    "# Add axis labels and legends\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.savefig('data/MSFT_bb.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In figure 2 we observe MSFT’s volatility behavior, with a similar behavior to the volatility of AAPL, MSFT’s volatility expands, contracts, and starts expanding back again for the remaining of the year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logarithmic Return distributions, Value at Risk and Conditional Value at Risk "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the logarithmic returns (log) for each stock to model Value at Risk (VaR). For this, we take the natural logarithm of the division between the current price and the previous price. This will give us a lognormal distribution of returns. With the log returns, we can plot a sorted distribution into a probability density function (PDF) to explain the VaR for a one-day period and the expected shortfall (CVaR) for a more coherent risk measurement for each stock. For all the VaR and CVaR computations, we use a 95% confidence interval. \n",
    "\n",
    "A measure of skew between `-2` and `+2` AND kurtosis is between `-7` and `+7` is considered normal.\n",
    "\n",
    "A measure of lower kurtosis has less outliers in the data than a normal distribution. Price stability is one way this can be looked at. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR parameters\n",
    "brk_ret = returns['AAPL']\n",
    "MSFT_ret = returns['MSFT']\n",
    "\n",
    "distribution = brk_ret*100\n",
    "confidence = 5\n",
    "last_value = brk_ret.mean()*100\n",
    "\n",
    "# Value at Risk\n",
    "price_array = distribution.sort_values(ascending=True)\n",
    "var_percentile = np.percentile(price_array, confidence)\n",
    "val_at_risk = last_value - var_percentile\n",
    "\n",
    "# CVaR\n",
    "cvar = price_array[price_array <= var_percentile].mean()\n",
    "\n",
    "# print\n",
    "var_percentile_95 = np.percentile(price_array, 5)\n",
    "\n",
    "val_at_risk_95 = last_value - var_percentile_95\n",
    "\n",
    "print(\"5.0% VaR threshold:\",round(var_percentile_95,4))\n",
    "\n",
    "# Conditional VaR\n",
    "cvar_95 = price_array[price_array <= var_percentile_95].mean()\n",
    "c_val_at_risk_95 = last_value - cvar_95\n",
    "\n",
    "print(\"5.0% CVaR:\",round(cvar_95,4))\n",
    "\n",
    "# Probabilistic Density Function\n",
    "mu = price_array.mean() \n",
    "sigma = price_array.std()  \n",
    "kurtosis = price_array.kurtosis()\n",
    "skewness = price_array.skew()\n",
    "num_bins = int(np.sqrt(len(distribution)))\n",
    "\n",
    "print(\"Kurtosis:\",kurtosis)\n",
    "print(\"skewness:\",skewness)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(price_array, num_bins, density=1,color=\"#002080\",label='',alpha=0.95)\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.xlabel('Returns (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks()\n",
    "plt.ylabel('Probability density')\n",
    "ax.set_title(\"VaR for AAPL\\nMu = %.3f, Sigma = %.3f, Kurtosis = %.3f \\n\" % (mu,sigma,kurtosis), fontsize=12)\n",
    "#plt.title(r'VaR for Simulated Prices', fontsize=18, fontweight='bold')\n",
    "plt.axvline(x=var_percentile, color='#ff4d4d', linestyle='--',linewidth=2, label='VaR at {}%: '.format(str(float(100-confidence))) + str(round(var_percentile,3)))\n",
    "plt.axvline(x=cvar, color='r', linestyle='-',linewidth=2, label='CVaR at {}% VaR: '.format(str(float(100-confidence))) + str(round(cvar,3)))\n",
    "plt.axvline(x=last_value, color='w', linestyle='dashed',linewidth=2, label = 'Mean: ' + str(round(last_value,3)))\n",
    "ax.set_facecolor('w')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('data/AAPL_var.png', dpi=300,bbox_inches='tight')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In figure 3, we observe the logarithmic return distribution for AAPL with a value at risk at -1.91% and an expected shortfall of -3.56%. The returns have an annualized daily return of 0.007% and an annualized volatility of 1.35% and a Sharpe ratio of 0.005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR parameters\n",
    "distribution = MSFT_ret*100\n",
    "confidence = 5\n",
    "last_value = MSFT_ret.mean()*100\n",
    "\n",
    "# Value at Risk\n",
    "price_array = distribution.sort_values(ascending=True)\n",
    "var_percentile = np.percentile(price_array, confidence)\n",
    "val_at_risk = last_value - var_percentile\n",
    "\n",
    "# CVaR\n",
    "cvar = price_array[price_array <= var_percentile].mean()\n",
    "\n",
    "# print\n",
    "var_percentile_95 = np.percentile(price_array, 5)\n",
    "\n",
    "val_at_risk_95 = last_value - var_percentile_95\n",
    "\n",
    "print(\"5.0% VaR threshold:\",round(var_percentile_95,4))\n",
    "\n",
    "# Conditional VaR\n",
    "cvar_95 = price_array[price_array <= var_percentile_95].mean()\n",
    "c_val_at_risk_95 = last_value - cvar_95\n",
    "\n",
    "print(\"5.0% CVaR:\",round(cvar_95,4))\n",
    "\n",
    "# Probabilistic Density Function\n",
    "mu = price_array.mean() \n",
    "sigma = price_array.std()  \n",
    "kurtosis = price_array.kurtosis()\n",
    "skewness = price_array.skew()\n",
    "num_bins = int(np.sqrt(len(distribution)))\n",
    "\n",
    "print(\"Kurtosis:\",kurtosis)\n",
    "print(\"skewness:\",skewness)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(price_array, num_bins, density=1,color=\"#FFA200\",label='',alpha=0.95)\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.xlabel('Returns (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks()\n",
    "plt.ylabel('Probability density')\n",
    "ax.set_title(\"VaR for MSFT\\nMu = %.3f, Sigma = %.3f, Kurtosis = %.3f \\n\" % (mu,sigma,kurtosis), fontsize=12)\n",
    "#plt.title(r'VaR for Simulated Prices', fontsize=18, fontweight='bold')\n",
    "plt.axvline(x=var_percentile, color='#ff4d4d', linestyle='--',linewidth=2, label='VaR at {}%: '.format(str(float(100-confidence))) + str(round(var_percentile,3)))\n",
    "plt.axvline(x=cvar, color='r', linestyle='-',linewidth=2, label='CVaR at {}% VaR: '.format(str(float(100-confidence))) + str(round(cvar,3)))\n",
    "plt.axvline(x=last_value, color='w', linestyle='dashed',linewidth=2, label = 'Mean: ' + str(round(last_value,3)))\n",
    "ax.set_facecolor('w')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"data/MSFT_var.png\", dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In figure 4, we notice the logarithmic returns distribution for MSFT with a VaR of -3.03% and a CVaR of -4.30% and an annualized return of 0.009 with an annualized volatility of 1.78%  and a Sharpe ratio of 0.0048. The risk measurements for each stock denote that at a one-day period, the stocks have a probability of reaching a potential loss up till the VaR threshold previously explained. With the CVaR, we can explain a more coherent measurement of the expected shortfall or the maximum risk at a given day (without counting total loss), as it takes into consideration the average of all the negative returns surpassing the VaR threshold. In this case, we can observe that AAPL has a VaR and CVaR threshold set higher than that of MSFT’s, explaining that with a constant probability of an expected shortfall for the following day, MSFT is much more exposed to a greater loss. We also computed the annualized beta for each stock’s return, using SPY as the benchmark. AAPL got an annualized beta of 1.35 and MSFT an annualized beta of 1.78. With this, we could further comprehend MSFT’s higher volatility than that of the US market’s primary benchmark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns Normality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more detailed analysis in the behavior of the logarithmic returns distribution for each stock, we introduce the following statistical methods to understand the distribution of returns for the past 252 days: excess kurtosis, skewness, and Shapiro-Wilk test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for normality on returns\n",
    "from scipy import stats\n",
    "\n",
    "# AAPL Normality\n",
    "print(\"AAPL Kurtosis: \", brk_ret.kurtosis())\n",
    "print(\"AAPL Skewness: \", brk_ret.skew())\n",
    "\n",
    "p_value = stats.shapiro(brk_ret)[1] \n",
    "\n",
    "if p_value <= 0.05:\n",
    "    print(\"Null hypothesis of normality is rejected.\") \n",
    "else:\n",
    "    print(\"Null hypothesis of normality is accepted.\")\n",
    "\n",
    "# MSFT Normality\n",
    "print(\"\\nMSFT Kurtosis: \", MSFT_ret.kurtosis())\n",
    "print(\"MSFT Skewness: \", MSFT_ret.skew())\n",
    "\n",
    "p_value = stats.shapiro(MSFT_ret)[1] \n",
    "\n",
    "if p_value <= 0.05:\n",
    "    print(\"Null hypothesis of normality is rejected.\") \n",
    "else:\n",
    "    print(\"Null hypothesis of normality is accepted.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For AAPL we obtained an excess kurtosis of 4.38, this means that the distribution of returns for AAPL has much more exposure in the tails and diverges significantly from the excess kurtosis of a normal distribution which is 0. In the case of MSFT, its excess kurtosis is of 3.14, which still explains a high level of kurtosis. These levels of kurtosis describe both AAPL and MSFT’s returns highly leptokurtic. Furthermore, the skewness of BRKA’s returns is -0.54 and -0.81 for MSFT’s. the negative skewness describes that the mass of the return distributions is concentrated on the right and therefore makes them right-leaning curves. By being right-leaning, the probability density of negative returns is much higher for both stocks.  Finally, we use the statistical Shapiro-Wilk test. This test has its null hypothesis that the distribution is normally distributed. We compute the p-value for each distribution and set the p-value threshold to a confidence interval of 95%. In the results, we got that both distributions have their null hypothesis rejected. This finally concludes that neither stock return distribution behaves in a normal way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Drawdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we compute the rolling cumulative returns for each stock to find the maximum drawdown for the past trading-year as a last risk measurement. Maximum drawdown explains the longest gap between the highest peak and lowest trough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum drawdown for AAPL\n",
    "\n",
    "# Calculating daily drawdowns for the past year\n",
    "cum_rets = np.cumsum(brk_ret)*100\n",
    "\n",
    "end = np.argmax(np.maximum.accumulate(cum_rets) - cum_rets) # end of the period\n",
    "start = np.argmax(cum_rets[:end]) # start of period\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = cum_rets.plot(title=\"AAPL Maximum Drawdown\",color=\"#002080\",label='AAPL') \n",
    "plt.plot([end, start], [cum_rets[end], cum_rets[start]], '--', color='Red', markersize=10,label='Maximum Drawdown',linewidth=2)\n",
    "plt.plot([end, start], [cum_rets[end], cum_rets[start]], 'o', color='Red', markersize=8,markeredgecolor='k')\n",
    "\n",
    "maximum_dd = abs(cum_rets[end]- cum_rets[start])\n",
    "print(\"AAPL's maximum drawdown starting from {} to {} with a duration of {}.\".format(start.date(),end.date(),end-start))\n",
    "print(\"AAPL's Maximum drawdown of {}%.\".format(round(maximum_dd,2)))\n",
    "\n",
    "# Add axis labels and legends\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Cumulative Returns (%)\")\n",
    "ax.legend(loc='lower right')\n",
    "plt.savefig('data/AAPL_mdd.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of AAPL, we can observe that the maximum drawdown in this year started in January 26 of 2018 and ended in June 27 of the same year with a duration of 152 days. The maximum drawdown for AAPL in percentage was of 14.61%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Drawdown for MSFT\n",
    "\n",
    "# Calculating daily drawdowns for the past year\n",
    "cum_rets = np.cumsum(MSFT_ret)*100\n",
    "\n",
    "end = np.argmax(np.maximum.accumulate(cum_rets) - cum_rets) # end of the period\n",
    "start = np.argmax(cum_rets[:end]) # start of period\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = cum_rets.plot(title=\"MSFT Maximum Drawdown\",color=\"#FFA200\",label='MSFT') \n",
    "plt.plot([end, start], [cum_rets[end], cum_rets[start]], '--', color='Red', markersize=10,label='Maximum Drawdown',linewidth=2)\n",
    "plt.plot([end, start], [cum_rets[end], cum_rets[start]], 'o', color='Red', markersize=8,markeredgecolor='k')\n",
    "\n",
    "maximum_dd = abs(cum_rets[end]- cum_rets[start])\n",
    "print(\"MSFT's maximum drawdown starting from {} to {} with a duration of {}.\".format(start.date(),end.date(),end-start))\n",
    "print(\"MSFT's Maximum drawdown of {}%.\".format(round(maximum_dd,2)))\n",
    "\n",
    "# Add axis labels and legends\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Cumulative Returns (%)\")\n",
    "ax.legend(loc='upper right')\n",
    "plt.savefig('data/MSFT_mdd.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of MSFT, the maximum drawdown in this year started from May 21st 2018 to December 10th of the same year with a duration of 203 days. The maximum drawdown for MSFT in percentage was of 26.51%. With this, we conclude MSFT’s high and long-lasting maximum drawdown as our last factor to determine MSFT’s much riskier investment based in the back-testing period for the past trading-year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk adjusted returns\n",
    "\n",
    "# Sharpe Ratio AAPL\n",
    "cagr_b = brk_ret.mean()\n",
    "vol_b = brk_ret.std()\n",
    "sharpe_b = cagr_b/vol_b\n",
    "print(\"CAGR for AAPL: \", round(cagr_b*100,4))\n",
    "print(\"Volatility for AAPL: \", round(vol_b*100,4))\n",
    "print(\"Sharpe for AAPL: \", round(sharpe_b,4))\n",
    "\n",
    "# Sharpe Ratio MSFT\n",
    "cagr_l = MSFT_ret.mean()\n",
    "vol_l = MSFT_ret.std()\n",
    "sharpe_l = cagr_l/vol_l\n",
    "print(\"\\nCAGR for MSFT: \", round(cagr_l*100,4))\n",
    "print(\"Volatility for MSFT: \", round(vol_l*100,4))\n",
    "print(\"Sharpe for MSFT: \", round(sharpe_l,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Eigen-Portfolio-4pNdkvCn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f924d061b96c5b77f783c830a509945d95ec4018972828647ff4a904f1d7a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
